{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing data set with sepsis features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Age', 'Gender', 'HospAdmTime', 'ICULOS', 'SepsisLabel']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "path = \"../training/\"\n",
    "paths = [path + \"p0\" + str(10000+i)[1:] + \".psv\" for i in range(1, 5001)]\n",
    "data = np.array([np.loadtxt(open(path + file), delimiter='|', skiprows=1) for file in paths])\n",
    "keys = open(paths[0]).readline().rstrip().split('|')\n",
    "\n",
    "def delete_columns_nan(data,keys):\n",
    "    df = {}\n",
    "    for i, column in enumerate(data.T):\n",
    "        if not np.isnan(column).all():\n",
    "            df[keys[i]] = column\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_nan_by_value(data, value=None):\n",
    "    for j, patient in enumerate(data):\n",
    "        for key in patient.keys():\n",
    "            if value == 'normal':\n",
    "                for i in range(len(patient[key])):\n",
    "                    p = patient[key].copy()[~np.isnan(patient[key])]\n",
    "                    if np.isnan(patient[key][i]):\n",
    "                        if value == 'mean':\n",
    "                            data[j][key][i] = np.mean(p)\n",
    "                        if value == 'normal':\n",
    "                            data[j][key][i] = np.random.normal(np.mean(p), np.std(p))\n",
    "            else:\n",
    "                patient[key] = np.nan_to_num(patient[key])\n",
    "    return data\n",
    "\n",
    "data_aux = []\n",
    "for patient in data:\n",
    "    data_aux.append(delete_columns_nan(patient, keys))\n",
    "\n",
    "# Count non-EMPTY entries throughout patients\n",
    "df = {}\n",
    "for key in keys:\n",
    "    df[key] = 0\n",
    "\n",
    "for patient in data_aux:\n",
    "    for key in patient.keys():\n",
    "        df[key] += 1\n",
    "    \n",
    "    \n",
    "data_new = replace_nan_by_value(data_aux, None)\n",
    "\n",
    "data_aux = []\n",
    "sepsis_keys = {}\n",
    "df = {}\n",
    "\n",
    "for key in keys:\n",
    "    df[key] = 0\n",
    "    sepsis_keys[key] = 0\n",
    "\n",
    "for patient in data:\n",
    "    data_aux.append(delete_columns_nan(patient, keys))\n",
    "    if np.any(data_aux[-1]['SepsisLabel']) == 1:\n",
    "        for key in data_aux[-1].keys():\n",
    "            sepsis_keys[key] += 1\n",
    "\n",
    "keys_s = []\n",
    "for key in sepsis_keys.keys():\n",
    "    if sepsis_keys[key] == np.max(list(sepsis_keys.values())):\n",
    "        keys_s.append(key)\n",
    "print(keys_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = []\n",
    "for patient in data_new:\n",
    "    if len(keys_s & patient.keys()) == len(keys_s):\n",
    "        new_dataset.append([patient[d] for d in keys_s])\n",
    "new_dataset = np.hstack(new_dataset).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 18795  18796  18797 ... 187945 187946 187947] TEST: [    0     1     2 ... 18792 18793 18794]\n",
      "0.10505836575875487\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [18795 18796 18797 ... 37587 37588 37589]\n",
      "0.06179775280898876\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [37590 37591 37592 ... 56382 56383 56384]\n",
      "0.14661654135338348\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [56385 56386 56387 ... 75177 75178 75179]\n",
      "0.02252252252252252\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [75180 75181 75182 ... 93972 93973 93974]\n",
      "0.010666666666666666\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [ 93975  93976  93977 ... 112767 112768 112769]\n",
      "0.031168831168831165\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [112770 112771 112772 ... 131562 131563 131564]\n",
      "0.011869436201780416\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [131565 131566 131567 ... 150357 150358 150359]\n",
      "0.0\n",
      "TRAIN: [     0      1      2 ... 187945 187946 187947] TEST: [150360 150361 150362 ... 169151 169152 169153]\n",
      "0.014134275618374558\n",
      "TRAIN: [     0      1      2 ... 169151 169152 169153] TEST: [169154 169155 169156 ... 187945 187946 187947]\n",
      "0.06128133704735376\n"
     ]
    }
   ],
   "source": [
    "x = new_dataset[:,:-1]\n",
    "y = new_dataset[:,-1]\n",
    "loo = LeaveOneOut()\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     random_forest = rf(n_estimators=10)\n",
    "#     random_forest = random_forest.fit(X_train, y_train)\n",
    "#     results = random_forest.predict(X_test)\n",
    "#     print(f1_score(y_test, results))\n",
    "    \n",
    "#     svm_c = svm.SVC(gamma='auto')\n",
    "#     svm_c = svm_c.fit(X_train, y_train)\n",
    "#     results = svm_c.predict(X_test)\n",
    "#     print(f1_score(y_test, results))\n",
    "    \n",
    "    knear = knn()\n",
    "    knear = knear.fit(X_train, y_train)\n",
    "    results = knear.predict(X_test)\n",
    "    print(f1_score(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
